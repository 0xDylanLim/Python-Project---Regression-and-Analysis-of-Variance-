import numpy as np
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
import sklearn.metrics as metrics
import matplotlib.pyplot as plt
import seaborn as sns

df_original = pd.read_csv("Invistico_Airline.csv")

df_original.head(n = 10)
df_original.dtypes
df_original['satisfaction'].value_counts(dropna = False)

#drop missing rows
df_original.isnull().sum()
df_subset = df_original.dropna(axis=0).reset_index(drop = True)

#prepare data
df_subset = df_subset.astype({"Inflight entertainment": float})

#convert categorical into numerical
OneHotEncoder(drop='first').fit_transform(df_subset[['satisfaction']])


#create a training and testing data
X = df_subset[["Inflight entertainment"]]
y = df_subset["satisfaction"]
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)

#MODEL BUILDING
#fit a logistic regression and fit the model to the training data.
clf = LogisticRegression().fit(X_train,y_train)
clf.coef_
clf.intercept_

#plot of model
sns.regplot(x="Inflight entertainment", y="satisfaction", data=df_subset, logistic=True, ci=None)

#predict the outcome for the test dataset
y_pred = clf.predict(X_test)
print(y_pred)
#output a probability
clf.predict_proba(X_test)
# output 0's and 1's.
clf.predict(X_test)

#Print out the model's accuracy, precision, recall, and F1 score.
print("Accuracy:", "%.6f" % metrics.accuracy_score(y_test, y_pred))
print("Precision:", "%.6f" % metrics.precision_score(y_test, y_pred))
print("Recall:", "%.6f" % metrics.recall_score(y_test, y_pred))
print("F1 Score:", "%.6f" % metrics.f1_score(y_test, y_pred))

#produce a confusion matrix
cm = metrics.confusion_matrix(y_test, y_pred, labels = clf.classes_)
disp = metrics.ConfusionMatrixDisplay(confusion_matrix = cm,display_labels = clf.classes_)
disp.plot()
